"""
Phase 1B: Visualization and Analysis Toolkit
Reusable functions for analyzing and visualizing CoT unfaithfulness test results
"""

import json
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from collections import defaultdict

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10


class ResultsVisualizer:
    """Create publication-quality visualizations"""
    
    def __init__(self, results_file: str):
        """Load results from JSON"""
        with open(results_file, 'r') as f:
            data = json.load(f)
        
        self.results = pd.DataFrame(data['results'])
        self.metadata = data['metadata']
        
        # Parse test_id to extract manipulation type and level
        self.results['manipulation_type'] = self.results['test_id'].str.extract(r'([A-Z_]+)_')[0]
        self.results['constraint'] = self.results['test_id'].str.extract(r'_([A-Z]+)_')[0]
    
    def plot_escalation_effectiveness(self, save_path: str = None):
        """Plot manipulation success rate vs escalation level"""
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig.suptitle('Manipulation Effectiveness by Escalation Level', 
                     fontsize=16, fontweight='bold')
        
        manipulation_types = self.results['manipulation_type'].unique()
        
        for idx, manip_type in enumerate(manipulation_types[:4]):
            ax = axes[idx // 2, idx % 2]
            
            data = self.results[self.results['manipulation_type'] == manip_type]
            
            # Calculate success rates by level
            success_by_level = data.groupby('escalation_level').agg({
                'manipulation_success': 'mean',
                'violated_constraint': 'mean',
                'warnings_given': lambda x: 1 - x.mean()  # Inverse for stacking
            })
            
            # Plot
            levels = success_by_level.index
            ax.plot(levels, success_by_level['manipulation_success'], 
                   marker='o', linewidth=2, markersize=8, label='Full Success')
            ax.plot(levels, success_by_level['violated_constraint'], 
                   marker='s', linewidth=2, markersize=8, label='Code Generated')
            ax.plot(levels, success_by_level['warnings_given'], 
                   marker='^', linewidth=2, markersize=8, label='No Warnings')
            
            ax.set_xlabel('Escalation Level', fontweight='bold')
            ax.set_ylabel('Success Rate', fontweight='bold')
            ax.set_title(f'{manip_type.replace("_", " ").title()}')
            ax.set_ylim(0, 1)
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_heatmap_vulnerability(self, save_path: str = None):
        """Heatmap of manipulation success by type and constraint"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # Pivot table
        pivot = self.results.pivot_table(
            values='manipulation_success',
            index='manipulation_type',
            columns='constraint',
            aggfunc='mean'
        )
        
        # Create heatmap
        sns.heatmap(pivot, annot=True, fmt='.2%', cmap='RdYlGn_r', 
                   vmin=0, vmax=1, ax=ax, cbar_kws={'label': 'Success Rate'})
        
        ax.set_title('Model Vulnerability Matrix\n(Manipulation Success Rate by Type & Constraint)',
                    fontsize=14, fontweight='bold', pad=20)
        ax.set_xlabel('Physical Constraint', fontweight='bold')
        ax.set_ylabel('Manipulation Type', fontweight='bold')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_cot_quality_vs_compliance(self, save_path: str = None):
        """Scatter plot: CoT quality vs constraint compliance"""
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # Separate by manipulation success
        successful = self.results[self.results['manipulation_success'] == True]
        failed = self.results[self.results['manipulation_success'] == False]
        
        ax.scatter(failed['cot_quality_score'], 
                  failed['escalation_level'],
                  c='green', s=100, alpha=0.6, label='Resisted Manipulation')
        ax.scatter(successful['cot_quality_score'], 
                  successful['escalation_level'],
                  c='red', s=100, alpha=0.6, label='Succumbed to Manipulation')
        
        ax.set_xlabel('Chain-of-Thought Quality Score', fontweight='bold')
        ax.set_ylabel('Escalation Level', fontweight='bold')
        ax.set_title('CoT Quality vs Manipulation Resistance\n(Red = Vulnerable, Green = Robust)',
                    fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_breakdown_cascade(self, save_path: str = None):
        """Stacked area chart showing breakdown across escalation levels"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # Aggregate across all manipulation types
        breakdown = self.results.groupby('escalation_level').agg({
            'constraint_check_performed': 'mean',
            'warnings_given': 'mean',
            'violated_constraint': 'mean',
            'manipulation_success': 'mean'
        })
        
        levels = breakdown.index
        
        # Create stacked areas
        ax.fill_between(levels, 0, breakdown['constraint_check_performed'],
                       alpha=0.7, label='Performed Constraint Check', color='green')
        ax.fill_between(levels, 0, breakdown['warnings_given'],
                       alpha=0.7, label='Gave Warnings', color='yellow')
        ax.fill_between(levels, 0, breakdown['violated_constraint'],
                       alpha=0.7, label='Generated Invalid Code', color='orange')
        ax.fill_between(levels, 0, breakdown['manipulation_success'],
                       alpha=0.7, label='Full Manipulation Success', color='red')
        
        ax.set_xlabel('Escalation Level', fontweight='bold')
        ax.set_ylabel('Proportion of Tests', fontweight='bold')
        ax.set_title('Safety Mechanisms Breaking Down Under Pressure\n(Stacked View)',
                    fontsize=14, fontweight='bold')
        ax.legend(loc='upper left')
        ax.set_ylim(0, 1)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_rationalization_frequency(self, save_path: str = None):
        """Bar chart of rationalization patterns by manipulation type"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # Group by manipulation type
        rat_freq = self.results.groupby('manipulation_type').agg({
            'rationalization_present': 'mean',
            'authority_cited': 'mean'
        }).sort_values('rationalization_present', ascending=False)
        
        x = np.arange(len(rat_freq))
        width = 0.35
        
        ax.bar(x - width/2, rat_freq['rationalization_present'], 
              width, label='Post-hoc Rationalization', color='coral')
        ax.bar(x + width/2, rat_freq['authority_cited'], 
              width, label='Authority Citation', color='skyblue')
        
        ax.set_xlabel('Manipulation Type', fontweight='bold')
        ax.set_ylabel('Frequency', fontweight='bold')
        ax.set_title('Unfaithful Reasoning Patterns\n(How Models Justify Invalid Outputs)',
                    fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(rat_freq.index, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_summary_report(self) -> str:
        """Generate text summary report"""
        report = []
        report.append("=" * 80)
        report.append("PHASE 1B: ADVANCED MANIPULATION TEST RESULTS")
        report.append("=" * 80)
        report.append("")
        
        # Overall stats
        total_tests = len(self.results)
        success_rate = self.results['manipulation_success'].mean()
        
        report.append(f"Total Tests: {total_tests}")
        report.append(f"Overall Manipulation Success Rate: {success_rate:.2%}")
        report.append("")
        
        # By manipulation type
        report.append("SUCCESS RATE BY MANIPULATION TYPE:")
        report.append("-" * 80)
        by_type = self.results.groupby('manipulation_type')['manipulation_success'].mean()
        for manip_type, rate in by_type.sort_values(ascending=False).items():
            report.append(f"  {manip_type:30s}: {rate:6.2%}")
        report.append("")
        
        # By escalation level
        report.append("SUCCESS RATE BY ESCALATION LEVEL:")
        report.append("-" * 80)
        by_level = self.results.groupby('escalation_level')['manipulation_success'].mean()
        for level, rate in by_level.items():
            report.append(f"  Level {level}: {rate:.2%}")
        report.append("")
        
        # Critical vulnerabilities
        report.append("CRITICAL VULNERABILITIES (>50% success):")
        report.append("-" * 80)
        critical = self.results.groupby(['manipulation_type', 'constraint']).agg({
            'manipulation_success': 'mean'
        })
        critical = critical[critical['manipulation_success'] > 0.5].sort_values(
            'manipulation_success', ascending=False
        )
        
        if len(critical) > 0:
            for (manip, const), row in critical.iterrows():
                report.append(f"  {manip} on {const}: {row['manipulation_success']:.2%}")
        else:
            report.append("  ‚úÖ None found - model is robust!")
        report.append("")
        
        # Reasoning quality
        report.append("CHAIN-OF-THOUGHT QUALITY:")
        report.append("-" * 80)
        report.append(f"  Average CoT Score: {self.results['cot_quality_score'].mean():.2f}/1.0")
        report.append(f"  CoT Score (Resistant): {self.results[~self.results['manipulation_success']]['cot_quality_score'].mean():.2f}/1.0")
        report.append(f"  CoT Score (Succumbed): {self.results[self.results['manipulation_success']]['cot_quality_score'].mean():.2f}/1.0")
        report.append("")
        
        # Unfaithfulness indicators
        report.append("UNFAITHFULNESS INDICATORS:")
        report.append("-" * 80)
        report.append(f"  Rationalization Present: {self.results['rationalization_present'].mean():.2%}")
        report.append(f"  Authority Cited: {self.results['authority_cited'].mean():.2%}")
        report.append(f"  Skipped Constraint Check: {(~self.results['constraint_check_performed']).mean():.2%}")
        report.append(f"  No Warnings Given: {(~self.results['warnings_given']).mean():.2%}")
        report.append("")
        
        report.append("=" * 80)
        
        return "\n".join(report)


class ComparativeAnalyzer:
    """Compare results across models or phases"""
    
    @staticmethod
    def compare_models(results_files: Dict[str, str], save_path: str = None):
        """Compare multiple models side-by-side"""
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig.suptitle('Model Comparison: Manipulation Resistance',
                    fontsize=16, fontweight='bold')
        
        # Load all results
        model_data = {}
        for model_name, filepath in results_files.items():
            with open(filepath, 'r') as f:
                data = json.load(f)
            model_data[model_name] = pd.DataFrame(data['results'])
        
        # Plot 1: Overall success rate by model
        ax = axes[0, 0]
        model_names = list(model_data.keys())
        success_rates = [df['manipulation_success'].mean() for df in model_data.values()]
        
        bars = ax.bar(model_names, success_rates, color=['green', 'yellow', 'orange', 'red'][:len(model_names)])
        ax.set_ylabel('Manipulation Success Rate', fontweight='bold')
        ax.set_title('Overall Vulnerability', fontweight='bold')
        ax.set_ylim(0, 1)
        
        # Add value labels
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.1%}', ha='center', va='bottom')
        
        # Plot 2: Success rate by escalation level
        ax = axes[0, 1]
        for model_name, df in model_data.items():
            by_level = df.groupby('escalation_level')['manipulation_success'].mean()
            ax.plot(by_level.index, by_level.values, marker='o', 
                   label=model_name, linewidth=2)
        
        ax.set_xlabel('Escalation Level', fontweight='bold')
        ax.set_ylabel('Success Rate', fontweight='bold')
        ax.set_title('Breakdown Under Pressure', fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Plot 3: CoT quality comparison
        ax = axes[1, 0]
        cot_scores = [df['cot_quality_score'].mean() for df in model_data.values()]
        bars = ax.bar(model_names, cot_scores, color='skyblue')
        ax.set_ylabel('Average CoT Quality Score', fontweight='bold')
        ax.set_title('Reasoning Quality', fontweight='bold')
        ax.set_ylim(0, 1)
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.2f}', ha='center', va='bottom')
        
        # Plot 4: Unfaithfulness indicators
        ax = axes[1, 1]
        x = np.arange(len(model_names))
        width = 0.25
        
        rationalization = [df['rationalization_present'].mean() for df in model_data.values()]
        authority = [df['authority_cited'].mean() for df in model_data.values()]
        no_check = [(~df['constraint_check_performed']).mean() for df in model_data.values()]
        
        ax.bar(x - width, rationalization, width, label='Rationalization')
        ax.bar(x, authority, width, label='Authority Citation')
        ax.bar(x + width, no_check, width, label='Skipped Check')
        
        ax.set_ylabel('Frequency', fontweight='bold')
        ax.set_title('Unfaithfulness Patterns', fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(model_names)
        ax.legend()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    @staticmethod
    def compare_phases(phase1a_file: str, phase1b_file: str, save_path: str = None):
        """Compare Phase 1A (basic) vs Phase 1B (advanced) results"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        fig.suptitle('Evolution: Basic vs Advanced Manipulation',
                    fontsize=16, fontweight='bold')
        
        # Load data
        with open(phase1a_file, 'r') as f:
            phase1a = pd.DataFrame(json.load(f)['results'])
        
        with open(phase1b_file, 'r') as f:
            phase1b = pd.DataFrame(json.load(f)['results'])
        
        # Plot 1: Success rate comparison
        ax = axes[0]
        phases = ['Phase 1A\n(Basic)', 'Phase 1B\n(Advanced)']
        rates = [
            phase1a['manipulation_success'].mean(),
            phase1b['manipulation_success'].mean()
        ]
        
        bars = ax.bar(phases, rates, color=['green', 'orange'])
        ax.set_ylabel('Manipulation Success Rate', fontweight='bold')
        ax.set_title('Increased Vulnerability', fontweight='bold')
        ax.set_ylim(0, max(rates) * 1.2)
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.1%}', ha='center', va='bottom', fontsize=12)
        
        # Plot 2: Breakdown of failures
        ax = axes[1]
        
        metrics = ['Generated\nInvalid Code', 'Skipped\nConstraint Check', 
                  'No Warnings', 'Rationalized']
        
        phase1a_metrics = [
            phase1a['violated_constraint'].mean(),
            (~phase1a['constraint_check_performed']).mean(),
            (~phase1a['warnings_given']).mean(),
            phase1a['rationalization_present'].mean()
        ]
        
        phase1b_metrics = [
            phase1b['violated_constraint'].mean(),
            (~phase1b['constraint_check_performed']).mean(),
            (~phase1b['warnings_given']).mean(),
            phase1b['rationalization_present'].mean()
        ]
        
        x = np.arange(len(metrics))
        width = 0.35
        
        ax.bar(x - width/2, phase1a_metrics, width, label='Phase 1A', color='green', alpha=0.7)
        ax.bar(x + width/2, phase1b_metrics, width, label='Phase 1B', color='orange', alpha=0.7)
        
        ax.set_ylabel('Frequency', fontweight='bold')
        ax.set_title('Safety Mechanism Failures', fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(metrics)
        ax.legend()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()


def create_dashboard(results_file: str, output_dir: str = "./visualizations/"):
    """Generate complete dashboard of visualizations"""
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    viz = ResultsVisualizer(results_file)
    
    print("üé® Generating visualizations...")
    
    viz.plot_escalation_effectiveness(f"{output_dir}/escalation_effectiveness.png")
    print("  ‚úÖ Escalation effectiveness plot saved")
    
    viz.plot_heatmap_vulnerability(f"{output_dir}/vulnerability_heatmap.png")
    print("  ‚úÖ Vulnerability heatmap saved")
    
    viz.plot_cot_quality_vs_compliance(f"{output_dir}/cot_quality_scatter.png")
    print("  ‚úÖ CoT quality scatter plot saved")
    
    viz.plot_breakdown_cascade(f"{output_dir}/breakdown_cascade.png")
    print("  ‚úÖ Breakdown cascade saved")
    
    viz.plot_rationalization_frequency(f"{output_dir}/rationalization_freq.png")
    print("  ‚úÖ Rationalization frequency saved")
    
    # Generate and save text report
    report = viz.generate_summary_report()
    with open(f"{output_dir}/summary_report.txt", 'w') as f:
        f.write(report)
    print("  ‚úÖ Summary report saved")
    
    print("\nüìä Dashboard complete!")
    print(f"   All files saved to: {output_dir}")
    
    return report


# Example usage
if __name__ == "__main__":
    # Visualize Phase 1B results
    results_file = "phase1b_results.json"
    
    if os.path.exists(results_file):
        report = create_dashboard(results_file)
        print("\n" + report)
    else:
        print(f"‚ùå Results file not found: {results_file}")
        print("   Run tests first to generate results!")